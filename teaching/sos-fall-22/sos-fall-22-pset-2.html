<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>sos-fall-22-pset-2</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="../../styling.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h2 id="problem-set-1">Problem Set 1</h2>
<p>Please turn in a PDF of typeset solutions solutions using LaTeX. Please turn in the pset by emailing me this pdf.</p>
<p><em>This pset may have bugs! Please email me, or reach out on Piazza, if you think there is a bug in a problem!</em></p>
<p>Due: TBD</p>
<p>You may use external resources such as Wikipedia to look up material which would reasonably be a prerequisite for this course (undergraduate-level algebra, linear algebra, probability, etc.). These exercises are designed to teach you something interesting about SoS and to acquaint you with an idea we won’t have time to cover in lecture. As such, solutions to some of them may appear in the research literature or in reference material for this course. Please avoid using such solutions, and if you find you have already read one, please set aside the corresponding problem for a few days before working on it again.</p>
<p><strong>Problem 1, 10 pts</strong> <em>(On “Satisfies,” borrowed from Aaron Potechin)</em>: Consider the following polynomial equation in <span class="math inline">\(3\)</span> variables, <span class="math inline">\(x,y,z\)</span>: <span class="math display">\[(x^2 + 1)y = z^2.\]</span> Since it implies <span class="math inline">\(y = z^2 / (1+x^2)\)</span>, clearly any solution <span class="math inline">\((x,y,z)\)</span> has <span class="math inline">\(y \geq 0\)</span>. We will see if SoS can capture this reasoning.</p>
<p><em>Part A:</em> Show that there is a degree-4 pseudoexpectation <span class="math inline">\(\tilde{\mathbb E}\)</span> in variables <span class="math inline">\(x,y,z\)</span> such that <span class="math inline">\(\tilde{\mathbb E}\vDash (x^2 + 1)y = z^2\)</span> but <span class="math inline">\(\tilde{\mathbb E}y &lt; 0\)</span>. (Computer-aided proofs are fine.) In this exercise, take <span class="math inline">\(\tilde{\mathbb E}\vdash (x^2 + 1)y = z^2\)</span>, where <span class="math inline">\(\tilde{\mathbb E}\)</span> is degree <span class="math inline">\(4\)</span>, to mean that for any degree <span class="math inline">\(\leq 1\)</span> polynomial <span class="math inline">\(p(x,y,z)\)</span>, we have <span class="math inline">\(\tilde{\mathbb E}p(x,y,z) (x^2 + 1)y = \tilde{\mathbb E}p(x,y,z) z^2\)</span>. (This differs slightly from the definition we gave in class.)</p>
<p><em>Part B:</em> Give an SoS refutation of the following system of inequalities, for any <span class="math inline">\(c &gt; 0\)</span>: <span class="math inline">\(\{ (x^2 + 1)y = z^2, y \leq -c \}\)</span>.</p>
<p><strong>Problem 2, 20 pts</strong> <em>(Robust Mean Estimation with Better Error Rates)</em>: Let <span class="math inline">\(D\)</span> be a distribution on <span class="math inline">\(\mathbb{R}^d\)</span>, with mean <span class="math inline">\(\mu\)</span>, such that <span class="math inline">\(\{ \|v\|^2 = 1 \} \vdash_{O(1)} \mathbb E_{X \sim D} \langle X-\mu,v \rangle^4 \leq 1\)</span>. (We saw that if <span class="math inline">\(D\)</span> is a centered Gaussian then this is true.) For simplicity, assume also that <span class="math inline">\(\|X\| \leq d^{O(1)}\)</span> with probability <span class="math inline">\(1\)</span> for <span class="math inline">\(X \sim D\)</span>.</p>
<p>In this problem you will show that there is a polynomial-time robust mean estimation algorithm which takes <span class="math inline">\(\varepsilon\)</span>-corrupted samples <span class="math inline">\(X_1,\ldots,X_n\)</span> from <span class="math inline">\(D\)</span> and returns <span class="math inline">\(\hat{\mu}\)</span> such that <span class="math inline">\(\|\hat{\mu} - \mu\| \leq O(\varepsilon^{3/4})\)</span>. (In class we proved only <span class="math inline">\(O(\sqrt \varepsilon)\)</span>.)</p>
<p><em>Part A:</em> Show that, with high probability over <span class="math inline">\(X_1,\ldots,X_n \sim D\)</span>, for <span class="math inline">\(n \leq d^{O(1)}\)</span>, <span class="math inline">\(\{\|v\| = 1\} \vdash_{O(1)} \frac 1 n \sum_{i \leq n} \langle X_i - \overline{\mu},v \rangle^4 \leq 1.01\)</span>, where <span class="math inline">\(\overline{\mu} = \frac 1 n \sum_{i \leq n} X_i\)</span>.</p>
<p><em>Part B:</em> Construct a system of equations <span class="math inline">\(Q_{Y_1,\ldots,Y_n}\)</span> in variables <span class="math inline">\(w_1,\ldots,w_n, X_1&#39;,\ldots,X_n&#39;\)</span>, and <span class="math inline">\((nd)^{O(1)}\)</span> auxiliary variables such that</p>
<ol type="i">
<li><p>if <span class="math inline">\(Y_1,\ldots,Y_n\)</span> are an <span class="math inline">\(\varepsilon\)</span>-corruption of any <span class="math inline">\(X_1,\ldots,X_n\)</span> for which the conclusion of Part A holds, and <span class="math inline">\(w_1,\ldots,w_n\)</span> are the indicators for <span class="math inline">\(i\)</span> such that <span class="math inline">\(X_i = Y_i\)</span>, and <span class="math inline">\(X_i&#39; = X_i\)</span>, then the auxiliary variables can be set so that <span class="math inline">\(Q\)</span> is satisfied, and</p></li>
<li><p><span class="math inline">\(Q \cup \{ \|v\|^2 = 1\} \vdash_{O(1)} \frac 1 n \sum_{i \leq n} \langle  X_i&#39; - \mu(X&#39;),v \rangle^4 \leq 1.01 \|v\|^2\)</span>, where <span class="math inline">\(\mu(X&#39;) = \frac 1 n \sum_{i \leq n} X_i&#39;\)</span>.</p></li>
</ol>
<p><em>Part C:</em> Show that the system of polynomials you constructed in Part B SoS-implies (in constant degree) the inequality <span class="math inline">\(\|\overline{\mu} - \mu(X&#39;)\|^t \leq O(\varepsilon^{3/4})^t\)</span>, for some even <span class="math inline">\(t\)</span>. (All whp over the non-corrupted samples <span class="math inline">\(X_1,\ldots,X_n\)</span>.)</p>
<p><em>Part D:</em> Describe a polynomial-time algorithm which achieves the robust mean estimation guarantee described above. (You don’t need to provide a full analysis.)</p>
<p><em>Part E:</em> Give 2 examples of non-Gaussian distributions on <span class="math inline">\(\mathbb{R}^d\)</span> which satisfy the hypotheses of this problem.</p>
<p><strong>Problem 3, 10 pts</strong> <em>(Univariate Polynomials)</em>: Let <span class="math inline">\(f(x) \, : \, \mathbb{R}\rightarrow \mathbb{R}\)</span> be a nonnegative polynomial with real coefficients. Prove that <span class="math inline">\(f\)</span> is a sum of squares. You may assume the following form of the fundamental theorem of algebra: every univariate polynomial with real coefficients of degree <span class="math inline">\(d\)</span> has exactly <span class="math inline">\(d\)</span> complex roots (counted with multiplicity).</p>
<p><strong>Problem 4, 10 pts</strong> <em>(Exact Matrix Completion)</em>: In class we saw a way to use SoS for matrix/tensor completion which incurred some error – for instance, using <span class="math inline">\(m\)</span> randomly-chosen entries from a low-rank <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(M\)</span> with entries in <span class="math inline">\([-1,1]\)</span>, we were able to find <span class="math inline">\(\hat{M}\)</span> such that <span class="math inline">\(|\hat{M}_{ij} - M| \approx n/m\)</span>.</p>
<p>In this problem we will see a glimpse of how to do better, by constructing a more sophisticated kind of SoS proof.</p>
<p>Let <span class="math inline">\(M\)</span> be an <span class="math inline">\(n \times n\)</span> matrix of rank <span class="math inline">\(r\)</span>, <span class="math inline">\(M = \sum_{i=1}^r a_i a_i^\top\)</span>, such that <span class="math inline">\(a_1,\ldots,a_r\)</span> are orthonormal and <span class="math inline">\(\|a_i\|_\infty \leq O(1/\sqrt n)\)</span>. It turns out that, under this assumption, if <span class="math inline">\(\Omega\)</span> is a randomly chosen set of <span class="math inline">\(m \gg r n (\log n)^2\)</span> entries of <span class="math inline">\(M\)</span>, then with high probability there exists a symmetric matrix <span class="math inline">\(A\)</span> such that <span class="math display">\[-0.9(I - M) \preceq A - M \preceq 0.9(I - M),\]</span> and furthermore, <span class="math inline">\(A\)</span> is nonzero only on entries in <span class="math inline">\(\Omega\)</span>. Intuitively, this says that there is a matrix <span class="math inline">\(A\)</span> which is zero off of <span class="math inline">\(\Omega\)</span> and which agrees perfectly with <span class="math inline">\(M\)</span> in directions <span class="math inline">\(a_1,\ldots,a_r\)</span>, incurring error only in the orthogonal complement of <span class="math inline">\(a_1,\ldots,a_r\)</span>.</p>
<p>(The construction of this matrix is not at all obvious and we will not investigate it here.)</p>
<p>Show the following consequence: if the matrix <span class="math inline">\(A\)</span> exists, then the following implication has a degree <span class="math inline">\(O(1)\)</span> SoS proof. If <span class="math inline">\(B\)</span> is an <span class="math inline">\(n \times r\)</span> matrix of variables, then <span class="math inline">\(\{ (BB^\top)_{ij} = M_{ij} \text{ for } ij \in \Omega, B^\top B = I_{r \times r} \} \vdash_{O(1)} \|BB^\top - M\|_F^2 = 0\)</span>. This says that the entries <span class="math inline">\(\Omega\)</span> perfectly identify <span class="math inline">\(M\)</span>, and furthermore that this identifiability has an SoS proof.</p>
<details>
<summary>
Problem 4 hints
</summary>
<p>Hint 1: First of all, it would be enough to give an SoS proof that <span class="math inline">\(\langle M, BB^\top \rangle \geq r\)</span> (prove this!).</p>
<p>Hint 2: Let’s think about what the two properties of <span class="math inline">\(A\)</span> allow us to <em>do</em> with it. First of all, since <span class="math inline">\(A\)</span> is zero off of <span class="math inline">\(\Omega\)</span>, if we have any two matrices <span class="math inline">\(C,D\)</span> whose <span class="math inline">\(\Omega\)</span> entries are identical, <span class="math inline">\(\langle A, C \rangle = \langle A,D \rangle\)</span>. Second, <span class="math inline">\(A\)</span> is a proxy for <span class="math inline">\(M\)</span> in the sense that for any PSD matrix <span class="math inline">\(X\)</span>, <span class="math inline">\(\langle A, X \rangle = \langle M,X \rangle \pm 0.9 \langle M^\perp, X \rangle\)</span>, where <span class="math inline">\(M^\perp = I - M\)</span> is the projector perpendicular to <span class="math inline">\(M\)</span>. This is especially useful if <span class="math inline">\(\langle M^\perp, X \rangle = 0\)</span>…</p>
<p>Hint 3: Can you lower-bound <span class="math inline">\(\langle M,BB^\top \rangle\)</span> using <span class="math inline">\(\langle A, BB^\top \rangle\)</span>? And then, can you lower bound <span class="math inline">\(\langle A, BB^\top \rangle\)</span> using <span class="math inline">\(\langle A, M \rangle\)</span> ? How big is this last quantity?</p>
</details>
</body>
</html>
